{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Online_shoppers_intention_HPO_MS_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MJJWt5SB4w3kNEy7g5Wc0u5hrhimVlDP",
      "authorship_tag": "ABX9TyMbuOUO2mKH7iPPkx3n/qdD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Titashmkhrj/Online-shopper-intention-project/blob/master/Online_shoppers_intention_HPO_MS_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOuux_xk1tig",
        "colab_type": "text"
      },
      "source": [
        "# Importing libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5bZFdP-wj2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0728de2c-ae85-433a-e4cf-649fa24821ec"
      },
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# importing the required libraries\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "import imblearn \n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import (LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import (RandomizedSearchCV, train_test_split, cross_val_score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Finished importing the libraries.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished importing the libraries.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d9n0Z1M2E66",
        "colab_type": "text"
      },
      "source": [
        "# Models objects and their parameter grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc3NwALDczVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# models as per the sequence in the parameter grid \n",
        "model_objects = [LogisticRegression(),\n",
        "                 LogisticRegression(),\n",
        "\t\t\t\t\t\t\t\t LogisticRegression(),\n",
        "\t\t\t\t\t\t\t\t PassiveAggressiveClassifier(),\n",
        "\t\t\t\t\t\t\t\t RidgeClassifier(),\n",
        "\t\t\t\t\t\t\t\t KNeighborsClassifier(),\n",
        "\t\t\t\t\t\t\t\t SVC(),\n",
        "\t\t\t\t\t\t\t\t DecisionTreeClassifier(),\n",
        "\t\t\t\t\t\t\t\t RandomForestClassifier()]\n",
        "\n",
        "\n",
        "\n",
        "# hyper-parameter dictionary for the tunningof the models\n",
        "parameter_grid = {'LR_l1' : {'model__penalty' : ['l1'],\n",
        "                              'model__C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                              'model__random_state' : [42],\n",
        "                              'model__solver' : ['liblinear', 'saga'],\n",
        "                              'model__max_iter' : [100000]\n",
        "                          },\n",
        "\t\t\t\t\n",
        "                  'LR_l2' : {'model__penalty' : ['l2'],\n",
        "                              'model__C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                              'model__random_state' : [42],\n",
        "                              'model__solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
        "                              'model__max_iter' : [100000]\n",
        "                          },\n",
        "\n",
        "                  'LR_ElNet' : {'model__penalty' : ['elasticnet'],\n",
        "                                'model__l1_ratio' : [0.3, 0.5, 0.7],\n",
        "                                'model__C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                                'model__random_state' : [42],\n",
        "                                'model__solver' : ['saga'],\n",
        "                                'model__max_iter' : [100000]\n",
        "                              },\n",
        "\n",
        "                  'Pass_Agg_clif' : {'model__C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                                    #   'model__fit_intercept' : ['True', 'False'],\n",
        "                                      'model__random_state' : [42],\n",
        "                                      'model__loss' : ['hinge', 'squared_hinge'],\n",
        "                                      'model__class_weight' : ['balanced', None]\n",
        "                                  },\n",
        "                  \n",
        "                  'Ridge_clif' : {'model__alpha' : [500.0, 50.0, 5.0, 0.5, 0.05, 0.005],\n",
        "                                  'model__fit_intercept' : ['True', 'False'],\n",
        "                                  'model__normalize' : ['True', 'False'],\n",
        "                                  'model__class_weight' : ['balanced', None],\n",
        "                                  'model__solver' : ['svd', 'cholesky', 'lsqr', 'sparse_cg']\n",
        "                              },\n",
        "                  \n",
        "                  'KN_classif' : {'model__n_neighbors' : [1,3,5,7,9],\n",
        "                                  'model__p' : [1,2,5]                     \n",
        "                              },\n",
        "                  \n",
        "                  'SVC' : {'model__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "                           'model__gamma' : ['scale', 'auto'],                     \n",
        "                      },\n",
        "                  \n",
        "                  'DT_clif' : {'model__criterion': ['gini','entropy'],\n",
        "                                'model__max_features': ['sqrt','log2',None],\n",
        "                                'model__min_samples_leaf': [1,2,5,10],\n",
        "                                'model__min_samples_split' : [2,5,10,15,100],\n",
        "                                'model__max_depth': [5,8,15,25,30,None]\n",
        "                          },\n",
        "                  \n",
        "                  'RF_clif' : {'model__n_estimators' : [120,300,500,800,1200],\n",
        "                               'model__max_features': ['sqrt','log2',None],\n",
        "                                'model__min_samples_leaf': [1,2,5,10],\n",
        "                                'model__min_samples_split' : [2,5,10,15,100],\n",
        "                                'model__max_depth': [5,8,15,25,30,None]                      \n",
        "                          }\n",
        "              }"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16aouJHM2zOR",
        "colab_type": "text"
      },
      "source": [
        " # Loading the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP7oMbnCxaHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading the feature and target spaces for our project\n",
        "x_data = pd.read_csv(\"/content/drive/My Drive/data_for_HPO&MS/Online_shopper's_intention/feature_space.csv\")\n",
        "y_data = pd.read_csv(\"/content/drive/My Drive/data_for_HPO&MS/Online_shopper's_intention/target_space.csv\")\n",
        "# dropping an unnecessary column from our feature and target space\n",
        "x_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "y_data.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWhQSIExii9",
        "colab_type": "text"
      },
      "source": [
        "# Splitting the data for the purpose of hyper-parameter optimisation and model selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ewZf15Hz1iR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21a6eb49-275b-4973-8660-58047b606214"
      },
      "source": [
        "# splitting our dataset into train, validation and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.3, random_state = 42)\n",
        "x_optimization, x_validation, y_optimization, y_validation = train_test_split(x_train, y_train, test_size = 0.3, random_state = 42)\n",
        "\n",
        "print(\"Finished splitting the data.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished splitting the data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sea9nOWIz5f3",
        "colab_type": "text"
      },
      "source": [
        "# Hyper-parameter optimisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ykKLF40Mzqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "717a13a3-9f48-464c-d154-9e94f6a9b213"
      },
      "source": [
        "# initiating an empty list for storing the optimized models\n",
        "hyper_parameter_optimized_models = []\n",
        "\n",
        "\n",
        "'''\n",
        "resampling our optimization datasets, in order to prevent overfitting of our models on the majority class of the target feature in our\n",
        "for the purpose above stated we will be using SMOTENC, which requires us to give the column indices of the categrical features\n",
        "'''\n",
        "catg_features_idx = []\n",
        "for feature in x_data.columns :\n",
        "    if len(x_data[feature].value_counts().index) == 2 :\n",
        "        catg_features_idx.append(list(x_data.columns).index(feature))\n",
        "# adding two more categorical features that have moe than two classes\n",
        "catg_features_idx.append(list(x_data.columns).index('SpecialDay'))\n",
        "catg_features_idx.append(list(x_data.columns).index('Month'))\n",
        "# arranging the list in ascending order\n",
        "catg_features_idx.sort()\n",
        "\n",
        "# making the resampling and standardising objects\n",
        "over_sampler = SMOTENC(categorical_features = catg_features_idx, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# initiating the random search\n",
        "for grid, model in zip(parameter_grid.values(), model_objects) :\n",
        "  # the only change that i have done is remove the comma \",\" from the end of the very next line i.e classif_model = ......\n",
        "  classif_model = Pipeline([('resampler', over_sampler), ('scaler', scaler), ('model', model)])\n",
        "  # the nex thing tht we can do is remove the over_sampler an scaler objects and define them in te pipeline itself\n",
        "  optimizer = RandomizedSearchCV(estimator = classif_model,\n",
        "\t\t\t\t\t\t\t\tparam_distributions = grid,\n",
        "\t\t\t\t\t\t\t\trandom_state = 42,\n",
        "\t\t\t\t\t\t\t\tcv = 3,\n",
        "\t\t\t\t\t\t\t\terror_score = -1,\n",
        "\t\t\t\t\t\t\t\tverbose = 10,\n",
        "\t\t\t\t\t\t\t\tn_jobs = -1,\n",
        "\t\t\t\t\t\t\t\t)\n",
        "  optimizer.fit(x_optimization, y_optimization.values.ravel())\n",
        "\t# appending the best estimator to a list\n",
        "  hyper_parameter_optimized_models.append(optimizer.best_estimator_)\n",
        "\n",
        "print('Hyper parameter tunning is finished.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   25.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   54.9s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   25.1s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   50.0s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   25.4s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   51.3s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   25.7s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   50.8s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   26.1s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   51.6s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   25.1s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  8.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   26.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   53.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  7.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   23.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   47.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   43.7s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  8.9min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 11.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hyper parameter tunning is finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qBWRc0-0Fww",
        "colab_type": "text"
      },
      "source": [
        "# Model selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb5WNBI40GR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed4ae1ea-1bb8-45a5-a437-3c9773b65d51"
      },
      "source": [
        "# initiating an empty list to stre the validation scores of the optimized models\n",
        "optimized_model_validation_scores = []\n",
        "\n",
        "for optimized_model in hyper_parameter_optimized_models :\n",
        "  optimized_model_pipeline = Pipeline([('resampler', over_sampler), ('scaler', scaler), ('optimized_model', optimized_model)])\n",
        "  model_validation_scores = cross_val_score(optimized_model_pipeline, x_validation, y_validation.values.ravel(), cv=3, n_jobs = -1)\n",
        "  optimized_model_validation_scores.append(np.mean(model_validation_scores))\n",
        "\n",
        "# making a dictionary to store the results of the hyper-parameter optimization and the model selection process.\n",
        "results_dict = {'optimized_model':hyper_parameter_optimized_models,\n",
        "                'validation_score':optimized_model_validation_scores\n",
        "                }\n",
        "\n",
        "optimized_model_results = pd.DataFrame(results_dict)\n",
        "# saving the results of the hyper-parameter optimization and model_selection in a csv file\n",
        "optimized_model_results.to_csv(\"/content/drive/My Drive/data_for_HPO&MS/Online_shopper's_intention/model_optimizaion_report.csv\")\n",
        "print('Model selection is finished')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model selection is finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_uStoB60HJe",
        "colab_type": "text"
      },
      "source": [
        "# Best performing hyper-parameter optimised model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olBhpvwX0Haj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c9d78a83-eb36-47bf-da3d-5a5b9dca6bd8"
      },
      "source": [
        "print('Initiating the process of our final phase to judge the average out-of-sample performance of our best found optimized model.')\n",
        "# selecting the best model by its index for the final predictions\n",
        "best_model_idx = optimized_model_results['validation_score'].idxmax(axis=0)\n",
        "best_model = optimized_model_results.iloc[best_model_idx,0]\n",
        "\n",
        "print('The best model to our finding is ', best_model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initiating the process of our final phase to judge the average out-of-sample performance of our best found optimized model.\n",
            "The best model to our finding is  Pipeline(memory=None,\n",
            "         steps=[('resampler',\n",
            "                 SMOTENC(categorical_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
            "                                               11, 12, 13, 14, 15, 16, 17, 18,\n",
            "                                               19, 20, 21, 22, 23, 24, 25, 26,\n",
            "                                               27, 28, 29, ...],\n",
            "                         k_neighbors=5, n_jobs=1, random_state=42,\n",
            "                         sampling_strategy='auto')),\n",
            "                ('scaler',\n",
            "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
            "                ('model',\n",
            "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
            "                                        class_weight=None, criterion='gini',\n",
            "                                        max_depth=25, max_features=None,\n",
            "                                        max_leaf_nodes=None, max_samples=None,\n",
            "                                        min_impurity_decrease=0.0,\n",
            "                                        min_impurity_split=None,\n",
            "                                        min_samples_leaf=2, min_samples_split=2,\n",
            "                                        min_weight_fraction_leaf=0.0,\n",
            "                                        n_estimators=300, n_jobs=None,\n",
            "                                        oob_score=False, random_state=None,\n",
            "                                        verbose=0, warm_start=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbD_ZYMI1uuL",
        "colab_type": "text"
      },
      "source": [
        "# Defining the best model from the above findings, that will be futher used for the final prediction making."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDDwBqYD1tzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c90e6088-cae7-463d-dc09-56710c9dbaf0"
      },
      "source": [
        "# selecting the classifier algorithm from the pipeline of the best model found.\n",
        "final_model = best_model[2]\n",
        "final_model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=25, max_features=None,\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=2, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6vMtqe_0H01",
        "colab_type": "text"
      },
      "source": [
        "# Final Prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcwIg8x60Huw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "34bde251-f4cc-4228-babc-53e99d7cc437"
      },
      "source": [
        "# we are utilizing the whole training dataset for training the fianl model before making predictions on the test set.\n",
        "# resampling our training datasets, in order to prevent overfitting of our models on the majority class of the target feature in our training set\n",
        "x_train_resampled, y_train_resampled = over_sampler.fit_resample(x_train, y_train)\n",
        "# dropping the sythetic feature after resampling is done\n",
        "y_train_resampled = pd.DataFrame(y_train_resampled, columns = y_train.columns)\n",
        "x_train_resampled = pd.DataFrame(x_train_resampled, columns = x_train.columns)\n",
        "\n",
        "# scaling our features in the training dataset\n",
        "scaler = StandardScaler().fit(x_train_resampled)\n",
        "x_train_scaled = scaler.transform(x_train_resampled)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# re-fitting out best found optimized model to the whole training set\n",
        "final_model.fit(x_train_scaled, y_train_resampled.values.ravel())\n",
        "out_of_sample_predictions = final_model.predict(x_test_scaled)\n",
        "\n",
        "final_score = accuracy_score(y_test, out_of_sample_predictions)\n",
        "\n",
        "print('The final average out-of-sample performance score of our best optimized model is', final_score)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The final average out-of-sample performance score of our best optimized model is 0.8821303054879697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JFiQ8w50Hl9",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlQh0ZAn1pOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce04665a-0bf7-4ef7-a5a1-6e46e34f47e9"
      },
      "source": [
        "# saving our best found optimized model for this data, as a pickle file\n",
        "joblib.dump(best_model, \"/content/drive/My Drive/data_for_HPO&MS/Online_shopper's_intention/best_model.pkl\")\n",
        "joblib.dump(final_model, \"/content/drive/My Drive/data_for_HPO&MS/Online_shopper's_intention/final_model.pkl\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"/content/drive/My Drive/data_for_HPO&MS/Online_shopper's_intention/final_model.pkl\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}